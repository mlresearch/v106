@Proceedings{MLHC-2019,
  booktitle =	 {Proceedings of the 4th Machine Learning for
                  Healthcare Conference},
  editor =	 {Finale Doshi-Velez and Jim Fackler and Ken Jung and
                  David Kale and Rajesh Ranganath and Byron Wallace
                  and Jenna Wiens},
  volume =	 {106},
  shortname =	 {MLHC},
  name =	 {Machine Learning for Healthcare Conference},
  year =	 {2019},
  start =	 {2019-08-09},
  end =		 {2019-08-10},
  published =	 {2019-10-28},
  address =	 {Ann Arbor, Michigan},
  url =		 {http://mlforhc.org/},
  conference_number ={4},
  shortname =	 {MLHC}
}

@inproceedings{Moor19,
  Abstract =	 {Sepsis is a life-threatening host response to
                  infection that is associated with high mortality,
                  morbidity, and health costs. Its management is
                  highly time-sensitive because each hour of delayed
                  treatment increases mortality due to irreversible
                  organ damage. Meanwhile, despite decades of clinical
                  research, robust biomarkers for sepsis are
                  missing. Therefore, detecting sepsis early by
                  utilizing the affluence of high-resolution intensive
                  care records has become a challenging machine
                  learning problem. Recent advances in deep learning
                  and data mining promise to deliver a powerful set of
                  tools to efficiently address this task. This
                  empirical study proposes two novel approaches for
                  the early detection of sepsis: a deep learning model
                  and a lazy learner that is based on time series
                  distances. Our deep learning model employs a
                  temporal convolutional network that is embedded in a
                  multi-task Gaussian Process adapter framework,
                  making it directly applicable to irregularly-spaced
                  time series data. In contrast, our lazy learner is
                  an ensemble approach that employs dynamic time
                  warping. We frame the timely detection of sepsis as
                  a supervised time series classification
                  task. Consequently, we derive the most recent sepsis
                  definition in an hourly resolution to provide the
                  first fully accessible early sepsis detection
                  environment. Seven hours before sepsis onset, our
                  methods improve area under the precision–recall
                  curve from 0.25 to 0.35 and 0.40, respectively, over
                  the state of the art. This demonstrates that they
                  are well-suited for detecting sepsis in the crucial
                  earlier stages when management is most effective.},
  Author =	 {Moor, Michael and Horn, Max and Rieck, Bastian and
                  Roqueiro, Damian and Borgwardt, Karsten},
  Booktitle =	 {Proceedings of the 4th Machine Learning for
                  Healthcare Conference},
  Pages =	 {2-26},
  Title =	 {Early Recognition of Sepsis with Gaussian Process
                  Temporal Convolutional Networks and Dynamic Time
                  Warping},
  Volume =	 {106},
  Year =	 {2019}
}

@inproceedings{Oh19,
  Abstract =	 {Recurrent neural networks (RNNs) are commonly
                  applied to clinical time-series data with the goal
                  of learning patient risk stratification
                  models. Their effectiveness is due, in part, to
                  their use of parameter sharing over time (i.e.,
                  cells are repeated hence the name recurrent ). We
                  hypothesize, however, that this trait also
                  contributes to the increased difficulty such models
                  have with learning relationships that change over
                  time. Conditional shift, i.e., changes in the
                  relationship between the input X and the output y,
                  arises when risk factors associated with the event
                  of interest change over the course of a patient
                  admission. While in theory, RNNs and gated RNNs
                  (e.g., LSTMs) in particular should be capable of
                  learning time-varying relationships, when training
                  data are limited, such models often fail to
                  accurately capture these dynamics. We illustrate the
                  advantages and disadvantages of complete parameter
                  sharing (RNNs) by comparing an LSTM with shared
                  parameters to a sequential architecture with
                  time-varying parameters on prediction tasks
                  involving three clinically-relevant outcomes: acute
                  respiratory failure (ARF), shock, and in-hospital
                  mortality. In experiments using synthetic data, we
                  demonstrate how parameter sharing in LSTMs leads to
                  worse performance in the presence of conditional
                  shift. To improve upon the dichotomy between
                  complete parameter sharing and no parameter sharing,
                  we propose a novel RNN formulation based on a
                  mixture model in which we relax parameter sharing
                  over time. The proposed method outperforms standard
                  LSTMs and other state-of-the-art baselines across
                  all tasks. In settings with limited data, relaxed
                  parameter sharing can lead to improved patient risk
                  stratification performance.},
  Author =	 {Oh, Jeeheh and Wang, Jiaxuan and Tang, Shengpu and
                  Sjoding, Michael W. and Wiens, Jenna},
  Booktitle =	 {Proceedings of the 4th Machine Learning for
                  Healthcare Conference},
  Pages =	 {27-52},
  Title =	 {Relaxed Parameter Sharing: Effectively Modeling
                  Time-Varying Relationships in Clinical Time-Series},
  Volume =	 {106},
  Year =	 {2019}
}

@inproceedings{Devarakonda19,
  Abstract =	 {Computational models that forecast the progression
                  of Alzheimer’s disease at the patient level are
                  extremely useful tools for identifying high risk
                  cohorts for early intervention and treatment
                  planning. The state-of-the-art work in this area
                  proposes models that forecast by using latent
                  representations extracted from the longitudinal data
                  across multiple modalities, including volumetric
                  information extracted from medical scans and
                  demographic info. These models incorporate the time
                  horizon, which is the amount of time between the
                  last recorded visit and the future visit, by
                  directly concatenating a representation of it to the
                  latent data representation. In this paper, we
                  present a model which generates a sequence of latent
                  representations of the patient status across the
                  time horizon, providing more informative modeling of
                  the temporal relationships between the patient’s
                  history and future visits. Our proposed model
                  outperforms the baseline in terms of forecasting
                  accuracy and F1 score.},
  Author =	 {Devarakonda, Surya Teja and Wu, Joie Yeahuay and
                  Fung, Yi Ren and Fiterau, Madalina},
  Booktitle =	 {Proceedings of the 4th Machine Learning for
                  Healthcare Conference},
  Pages =	 {53-65},
  Title =	 {FLARe: Forecasting by Learning Anticipated
                  Representations},
  Volume =	 {106},
  Year =	 {2019}
}

@inproceedings{Urteaga19,
  Abstract =	 {We present an end-to-end statistical framework for
                  personalized, accurate, and minimally invasive
                  modeling of female reproductive hormonal
                  patterns. Reconstructing and forecasting the
                  evolution of hormonal dynamics is a challenging
                  task, but a critical one to improve general
                  understanding of the menstrual cycle and
                  personalized detection of potential health
                  issues. Our goal is to infer and forecast individual
                  hormone daily levels over time, while accommodating
                  pragmatic and minimally invasive measurement
                  settings. To that end, our approach combines the
                  power of probabilistic generative models (i.e.,
                  multi-task Gaussian processes) with the flexibility
                  of neural networks (i.e., a dilated convolutional
                  architecture) to learn complex temporal mappings. To
                  attain accurate hormone level reconstruction with as
                  little data as possible, we propose a sampling
                  mechanism for optimal reconstruction accuracy with
                  limited sampling budget. Our results show the
                  validity of our proposed hormonal dynamic modeling
                  framework, as it provides accurate predictive
                  performance across different realistic sampling
                  budgets and outperforms baselines methods.},
  Author =	 {Urteaga, I{\~{n}}igo and Bertin, Tristan and Hardy,
                  Theresa M. and Albers, David J. and Elhadad,
                  No{\'{e}}mie},
  Booktitle =	 {Proceedings of the 4th Machine Learning for
                  Healthcare Conference},
  Pages =	 {66-90},
  Title =	 {Multi-Task Gaussian Processes and Dilated
                  Convolutional Networks for Reconstruction of
                  Reproductive Hormonal Dynamics},
  Volume =	 {106},
  Year =	 {2019}
}

@inproceedings{Akbari19,
  Abstract =	 {Blood glucose value prediction is an important task
                  in diabetes management. While it is reported that
                  glucose concentration is sensitive to social context
                  such as mood, physical activity, stress, diet,
                  alongside the influence of diabetes pathologies, we
                  need more research on data and methodologies to
                  incorporate and evaluate signals about such temporal
                  context into prediction models. Person-generated
                  data sources, such as actively contributed surveys
                  as well as passively mined data from social media
                  offer opportunity to capture such context, however
                  the self-reported nature and sparsity of such data
                  mean that such data are noisier and less specific
                  than physiological measures such as blood glucose
                  values themselves. Therefore, here we propose a
                  Gaussian Process model to both address these data
                  challenges and combine blood glucose and latent
                  feature representations of contextual data for a
                  novel multi-signal blood glucose prediction task. We
                  find this approach outperforms common methods for
                  multi-variate data, as well as using the blood
                  glucose values in isolation. Given a robust
                  evaluation across two blood glucose datasets with
                  different forms of contextual information, we
                  conclude that multi-signal Gaussian Processes can
                  improve blood glucose prediction by using contextual
                  information and may provide a significant shift in
                  blood glucose prediction research and practice.},
  Author =	 {Akbar, Mohammad and Chunara, Rumi},
  Booktitle =	 {Proceedings of the 4th Machine Learning for
                  Healthcare Conference},
  Pages =	 {91-108},
  Title =	 {Using Contextual Information to Improve Blood
                  Glucose Prediction},
  Volume =	 {106},
  Year =	 {2019}
}

@inproceedings{Nagpal19,
  Abstract =	 {Rapid detection of hemorrhage is of major interest
                  to the critical care community, enabling clinicians
                  to take swift actions to mitigate adverse
                  outcomes. In this paper, we describe a model that
                  allows rapid detection of the onset of hemorrhage by
                  monitoring the Central Venous Pressure (CVP). As
                  opposed to prior work in the domain, our model does
                  not rely on prior availability of a stable
                  physiology of a patient as a baseline of reference,
                  and it makes generative assumptions on the monitored
                  vital sign. This allows for rapid on-the-fly
                  personalization to a previously unseen patient’s
                  physiology. This property makes the proposed
                  approach particularly relevant to e.g. trauma care
                  and other scenarios where reference hemodynamic data
                  may not be readily available for any new patient. We
                  compare our model against strong discriminative
                  alternatives and demonstrate its potential utility
                  through empirical evaluation.},
  Author =	 {Nagpal, Chirag and Li, Xinyu and Pinsky, Michael
                  R. and Dubrawski, Artur},
  Booktitle =	 {Proceedings of the 4th Machine Learning for
                  Healthcare Conference},
  Pages =	 {109-123},
  Title =	 {Dynamically Personalized Detection of Hemorrhage},
  Volume =	 {106},
  Year =	 {2019}
}

@inproceedings{Shanmugam19,
  Abstract =	 {Patients who suffer an acute coronary syndrome are
                  at elevated risk for adverse cardiovascular events
                  such as myocardial infarction and cardiovascular
                  death. Accurate assessment of this risk is crucial
                  to their course of care. We focus on estimating a
                  patient's risk of cardiovascular death after an
                  acute coronary syndrome based on a patient's raw
                  electrocardiogram (ECG) signal. Learning from this
                  signal is challenging for two reasons: 1) positive
                  examples signifying a downstream cardiovascular
                  event are scarce, causing drastic class imbalance,
                  and 2) each patient's ECG signal consists of
                  thousands of heartbeats, accompanied by a single
                  label for the downstream outcome. Machine learning
                  has been previously applied to this task, but most
                  approaches rely on hand-crafted features and domain
                  knowledge. We propose a method that learns a
                  representation from the raw ECG signal by using a
                  multiple instance learning framework. We present a
                  learned risk score for cardiovascular death that
                  outperforms existing risk metrics in predicting
                  cardiovascular death within 30, 60, 90, and 365 days
                  on a dataset of 5000 patients.},
  Author =	 {Shanmugam, Divya and Blalock, Davis and Guttag,
                  John},
  Booktitle =	 {Proceedings of the 4th Machine Learning for
                  Healthcare Conference},
  Pages =	 {124-139},
  Title =	 {Multiple Instance Learning for ECG Risk
                  Stratification},
  Volume =	 {106},
  Year =	 {2019}
}

@inproceedings{Nagesh19,
  Abstract =	 {Glaucoma is the second leading global cause of
                  blindness and its effects are irreversible, making
                  early intervention crucial. The identification of
                  glaucoma progression is therefore a challenging and
                  important task. In this work, we model and predict
                  longitudinal glaucoma measurements using an
                  interpretable, discrete state space model. Two
                  common glaucoma biomarkers are the retinal nerve
                  fibre layer (RNFL) thickness and the visual eld
                  index (VFI). Prior works have frequently used a
                  scalar representation for RNFL, such as the average
                  RNFL thickness, thereby discarding
                  potentially-useful spatial information. We present a
                  technique for incorporating spatiotemporal RNFL
                  thickness measurements obtained from a sequence of
                  OCT images into a longitudinal progression
                  model. While these images capture the details of
                  RNFL thickness, representing them for use in a
                  longitudinal model poses two challenges: First,
                  spatial changes in RNFL thickness must be encoded
                  and organized into a temporal sequence in order to
                  enable state space modeling. Second, a predictive
                  model for forecasting the pattern of changes over
                  time must be developed. We address these challenges
                  through a novel approach to spatiotemporal
                  progression analysis. We jointly model the change in
                  RNFL with VFI using a CT-HMM and predict future
                  measurements. We achieve a decrease in mean absolute
                  error of 74\% for spatial RNFL thickness encoding in
                  comparison to prior work using the average RNFL
                  thickness. This work will be useful for accurately
                  predicting the spatial location and intensity of
                  tissue degeneration. Appropriate intervention based
                  on more accurate prediction can potentially help to
                  improve the clinical care of glaucoma.},
  Author =	 {Nagesh, Supriya and Moreno, Alexander and Ishikawa,
                  Hiroshi and Wollstein, Gadi and Shuman, Joel S. and
                  Rehg, James M.},
  Booktitle =	 {Proceedings of the 4th Machine Learning for
                  Healthcare Conference},
  Pages =	 {140-159},
  Title =	 {A Spatiotemporal Approach to Predicting Glaucoma
                  Progression Using a CT-HMM},
  Volume =	 {106},
  Year =	 {2019}
}

@inproceedings{Covert19,
  Abstract =	 {Seizure detection from EEGs is a challenging and
                  time-consuming clinical problem that would benefit
                  from the development of automated algorithms. EEGs
                  can be viewed as structural time series, because
                  they are multivariate time series where the
                  placement of leads on a patient's scalp provides
                  prior information about the structure of
                  interactions. Commonly used deep learning models for
                  time series do not offer a way to leverage
                  structural information, but this would be desirable
                  in a model for structural time series. To address
                  this challenge, we propose the temporal graph
                  convolutional network (TGCN), a model that leverages
                  temporal and structural information and has
                  relatively few parameters. TGCN applies feature
                  extraction operations that are localized and shared
                  over both time and space, thereby providing a useful
                  inductive bias in tasks where similar features are
                  expected to be discriminative across the different
                  sequences. In our experiments we focus on metrics
                  that are most important to seizure detection, and
                  demonstrate that TGCN matches the performance of
                  related models that have been shown to be
                  state-of-the-art in other tasks. Additionally, we
                  investigate interpretability advantages of TGCN by
                  exploring approaches for helping clinicians
                  determine when precisely seizures occur, and the
                  parts of the brain that are most involved.},
  Author =	 {Covert, Ian C. and Krishnan, Balu and Najm, Imad and
                  Zhan, Jiening and Shore, Matthew and Hixson, John
                  and Po, Ming Jack},
  Booktitle =	 {Proceedings of the 4th Machine Learning for
                  Healthcare Conference},
  Pages =	 {160-180},
  Title =	 {Temporal Graph Convolutional Networks for Automatic
                  Seizure Detection},
  Volume =	 {106},
  Year =	 {2019}
}

@inproceedings{Rudovic19,
  Abstract =	 {We introduce a novel personalized Gaussian Process
                  Experts (pGPE) model for predicting per-subject
                  ADAS-Cog13 cognitive scores – a significant
                  predictor of Alzheimer’s Disease (AD) in the
                  cognitive domain – over the future 6, 12, 18, and 24
                  months. We start by training a population-level
                  model using multi-modal data from previously seen
                  subjects using a base Gaussian Process (GP)
                  regression. Then, we personalize this model by
                  adapting the base GP sequentially over time to a new
                  (target) subject using domain adaptive GPs, and also
                  by training subject-specific GP. While we show that
                  these models achieve improved performance when
                  selectively applied to the forecasting task (one
                  performs better than the other on different
                  subjects/visits), the average performance per model
                  is suboptimal. To this end, we used the notion of
                  meta learning in the proposed pGPE to design a
                  regression-based weighting of these expert models,
                  where the expert weights are optimized for each
                  subject and his/her future visit. The results on a
                  cohort of subjects from the ADNI dataset show that
                  this newly introduced personalized weighting of the
                  expert models leads to large improvements in
                  accurately forecasting future ADAS-Cog13 scores and
                  their fine-grained changes associated with the AD
                  progression. This approach has potential to help
                  identify at-risk patients early and improve the
                  construction of clinical trials for AD.},
  Author =	 {Rudovic, Ognjen (Oggi) and Utsumi, Yuria and
                  Guerrero, Ricardo and Peterson, Kelly and Rueckert,
                  Daniel and Picard, Rosalind W.},
  Booktitle =	 {Proceedings of the 4th Machine Learning for
                  Healthcare Conference},
  Pages =	 {181-196},
  Title =	 {Meta-Weighted Gaussian Process Experts for
                  Personalized Forecasting of AD Cognitive Changes},
  Volume =	 {106},
  Year =	 {2019}
}

@inproceedings{Xu19,
  Abstract =	 {This study presents a multimodal machine learning
                  model to predict ICD-10 diagnostic codes. We
                  developed separate machine learning models that can
                  handle data from different modalities, including
                  unstructured text, semi-structured text and
                  structured tabular data. We further employed an
                  ensemble method to integrate all modality-specific
                  models to generate ICD codes. Key evidence was also
                  extracted to make our prediction more convincing and
                  explainable. We used the Medical Information Mart
                  for Intensive Care III (MIMIC-III) dataset to
                  validate our approach. For ICD code prediction, our
                  best-performing model (micro-F1 = 0.7633, micro-AUC
                  = 0.9541) significantly outperforms other baseline
                  models including TF-IDF (micro-F1 = 0.6721,
                  micro-AUC = 0.7879) and Text-CNN model (micro-F1 =
                  0.6569, micro-AUC = 0.9235). For interpretability,
                  our approach achieves a Jaccard Similarity Coecient
                  (JSC) of 0.1806 on text data and 0.3105 on tabular
                  data, where well-trained physicians achieve 0.2780
                  and 0.5002 respectively.},
  Author =	 {Xu, Keyang and Lam, Mike and Pang, Jingzhi and Gao,
                  Xin and Band, Charlotte and Mathur, Piyush and
                  Papay, Frank and Khanna, Ashish K. and Cywinski,
                  Jacek B. and Maheshwari, Kamal and Xie, Pengtao and
                  Xing, Eric P.},
  Booktitle =	 {Proceedings of the 4th Machine Learning for
                  Healthcare Conference},
  Pages =	 {197-215},
  Title =	 {Multimodal Machine Learning for Automated ICD
                  Coding},
  Volume =	 {106},
  Year =	 {2019}
}

@inproceedings{Rawat19,
  Abstract =	 {Clinical judgement studies are essential for
                  recognising the causal relation of a medication with
                  adverse drug reactions (ADRs). Traditionally, these
                  studies are conducted via expert manual chart
                  review. By contrast, we propose an end-to-end deep
                  learning question answering model to automatically
                  infer such causal relations. Our proposed model
                  identifies the causal relation by answering a subset
                  of Naranjo questionnaire Naranjo et al. (1981) from
                  electronic health records. It employs multi-level
                  attention layers along with local and global context
                  while answering these questions. Our proposed model
                  achieves a macro-weighted F-score of 0.4598 - 0.5142
                  across the selected questions and an overall F-score
                  of 0.5011. We also did an ablation study to validate
                  the importance of local and global context for the
                  model.},
  Author =	 {Rawat, Bhanu Pratap Singh and Li, Fe and Yu, Hong},
  Booktitle =	 {Proceedings of the 4th Machine Learning for
                  Healthcare Conference},
  Pages =	 {216-229},
  Title =	 {Clinical Judgement Study using Question Answering
                  from Electronic Health Records},
  Volume =	 {106},
  Year =	 {2019}
}

@inproceedings{Shin19,
  Abstract =	 {Predicting drug-target interactions (DTI) is an
                  essential part of the drug discovery process, which
                  is an expensive process in terms of time and
                  cost. Therefore, reducing DTI cost could lead to
                  reduced healthcare costs for a patient. In addition,
                  a precisely learned molecule representation in a DTI
                  model could contribute to developing personalized
                  medicine, which will help many patient cohorts. In
                  this paper, we propose a new molecule representation
                  based on the self-attention mechanism, and a new DTI
                  model using our molecule representation. The
                  experiments show that our DTI model outperforms the
                  state of the art by up to 4.9% points in terms of
                  area under the precision-recall curve. Moreover, a
                  study using the DrugBank database proves that our
                  model effectively lists all known drugs targeting a
                  specific cancer biomarker in the top-30 candidate
                  list.},
  Author =	 {Shin, Bonggun and Park, Sungsoo and Kang, Keunsoo
                  and Ho, Joyce C.},
  Booktitle =	 {Proceedings of the 4th Machine Learning for
                  Healthcare Conference},
  Pages =	 {230-248},
  Title =	 {Self-Attention Based Molecule Representation for
                  Predicting Drug-Target Interaction},
  Volume =	 {106},
  Year =	 {2019}
}

@inproceedings{Liu19,
  Abstract =	 {The automatic generation of radiology reports given
                  medical radiographs has significant potential to
                  operationally and improve clinical patient care. A
                  number of prior works have focused on this problem,
                  employing advanced methods from computer vision and
                  natural language generation to produce readable
                  reports. However, these works often fail to account
                  for the particular nuances of the radiology domain,
                  and, in particular, the critical importance of
                  clinical accuracy in the resulting generated
                  reports. In this work, we present a domain-aware
                  automatic chest X-ray radiology report generation
                  system which first predicts what topics will be
                  discussed in the report, then conditionally
                  generates sentences corresponding to these
                  topics. The resulting system is fine-tuned using
                  reinforcement learning, considering both readability
                  and clinical accuracy, as assessed by the proposed
                  Clinically Coherent Reward. We verify this system on
                  two datasets, Open-I and MIMICCXR, and demonstrate
                  that our model offers marked improvements on both
                  language generation metrics and CheXpert assessed
                  accuracy over a variety of competitive baselines.},
  Author =	 {Liu, Guanxiong and Hsu, Tzu-Ming Harry and
                  McDermott, Matthew and Boag, Willie and Weng,
                  Wei-Hung and Szolovits, Peter and Ghassemi, Marzyeh},
  Booktitle =	 {Proceedings of the 4th Machine Learning for
                  Healthcare Conference},
  Pages =	 {249-269},
  Title =	 {Clinically Accurate Chest X-Ray Report Generation},
  Volume =	 {106},
  Year =	 {2019}
}

@inproceedings{Kong19,
  Abstract =	 {Early prediction of neurodegenerative disorders such
                  as Alzheimer's disease (AD) and related dementias is
                  important in developing early medical supports and
                  social supports, and may identify ideal stages for
                  testing novel therapeutics aimed at preventing
                  disease progression. Currently, a diagnosis is based
                  on clinical expertise and cognitive screening tests,
                  which have limited accuracy in earlier stages of
                  disease, or invasive and resource-intensive testing,
                  such as lumbar puncture or specialized
                  neuroimaging. Changes in speech and language
                  patterns can occur in dementia in its earliest
                  stages and may worsen as the disease
                  progresses. This has led to recent attempts to
                  create automatic methods that predict dementia
                  through language analysis. In addition to features
                  extracted from language samples, previous works have
                  improved the prediction accuracy by introducing some
                  task-specific features. But task-specific features
                  prevent the model from generalizing to other
                  tests. In this paper, we apply a neural model
                  (Hierarchical Attention Networks) to the dementia
                  prediction task. Remarkably, the model requires no
                  task-specific feature and achieves state-of-the-art
                  classification result on a widely used dementia
                  dataset of spoken language. We also perform a detail
                  analysis to interpret how a prediction is
                  made. Interestingly, the same neural model does not
                  work well on a corpus of written text, suggesting
                  that dementia prediction from language may require
                  different methods depending on the genre of the
                  source language.},
  Author =	 {Kong, Weirui and Jang, Hyeju and Carenini, Giuseppe
                  and Field, Thalia},
  Booktitle =	 {Proceedings of the 4th Machine Learning for
                  Healthcare Conference},
  Pages =	 {270-286},
  Title =	 {A Neural Model for Predicting Dementia from
                  Language},
  Volume =	 {106},
  Year =	 {2019}
}

@inproceedings{Guan19,
  Abstract =	 {Reducing patients' medical wait times by improving
                  resource and staffing allocation is an important
                  area of focus in hospital operations management. Two
                  ways to decrease wait times are to adjust staffing
                  or to limit the number of non-urgent visits to
                  reflect a predicted volume of sick
                  patients. Currently, this problem has been
                  approached by both generalized linear models and
                  time series models, and has mainly been researched
                  in the context of adult emergency departments. We
                  analyze sick visit data over a nine year period from
                  one pediatric group (PG) that serves over 30,000
                  sick infants, children, and adolescents yearly in a
                  walk-in and appointment-based out-patient
                  clinic. The PG currently schedules staff and
                  well-child appointments assuming a constant number
                  of sick visits daily despite weekly and seasonal
                  cycles in the data. We develop time series models to
                  estimate the volume of sick patients that the PG can
                  expect on any given day, so that clinicians can be
                  allocated and the number of well-child appointments
                  scheduled in advance can be adjusted according to
                  predictions. First, we find that recurrent neural
                  network (RNN) models are able to capture the
                  seasonality of the data and perform substantially
                  better than state-of-the-art models, including
                  constant predictions. Next, we find that previous
                  days' data can be used to perform outbreak detection
                  by identifying error outliers. Lastly, we find
                  improvements in prediction when modeling sick
                  patients as a mixture of disease types, because
                  disease types are concentrated differently
                  throughout the year. Resource allocation based on
                  these findings can be expanded upon to reduce wait
                  time by improving staffing at pediatric emergency
                  departments and outpatient clinics.},
  Author =	 {Guan, Grace and Engelhardt, Barbara E.},
  Booktitle =	 {Proceedings of the 4th Machine Learning for
                  Healthcare Conference},
  Pages =	 {271-287},
  Title =	 {Predicting Sick Patient Volume in a Pediatric
                  Outpatient Setting using Time Series Analysis},
  Volume =	 {106},
  Year =	 {2019}
}

@inproceedings{Qi19,
  Abstract =	 {Predicting Phase 3 clinical trial results is a
                  critical step of Go/No-Go decision making and Phase
                  3 trial design optimization. To predict the overall
                  treatment effect for patients enrolled into a Phase
                  3 trial, we propose a framework consisting of two
                  models. First, an individual trough pharmacokinetic
                  concentration (Ctrough) model is developed to
                  predict the trough pharmacokinetic concentration for
                  a potentially new treatment regime planned for Phase
                  3. Second, an individual treatment effect model is
                  built to model the relationship between patient
                  baseline characteristics, Ctrough and clinical
                  outcomes. These two models are combined together to
                  predict Phase 3 clinical trial results. Since the
                  clinical outcomes to be predicted are longitudinal
                  and the predictors are a mix of time-invariant and
                  time-variant variables, a novel neural network,
                  Residual Semi-Recurrent Neural Network, is developed
                  for both models. The proposed framework is applied
                  in a post-hoc prediction of Phase 3 clinical trial
                  results, and it outperforms the traditional method.},
  Author =	 {Qi, Youran and Tang, Qi},
  Booktitle =	 {Proceedings of the 4th Machine Learning for
                  Healthcare Conference},
  Pages =	 {288-303},
  Title =	 {Predicting Phase 3 Clinical Trial Results by
                  Modeling Phase 2 Clinical Trial Subject Level Data
                  Using Deep Learning},
  Volume =	 {106},
  Year =	 {2019}
}

@inproceedings{Rodriguez19,
  Abstract =	 {Disease phenotyping algorithms are designed to sift
                  through clinical data stores to identify patients
                  with specific diseases. Supervised phenotyping
                  methods require significant quantities of
                  expert-labeled data, while unsupervised methods may
                  learn spurious or non-disease phenotypes. To address
                  these limitations, we propose the Semi-Supervised
                  Mixed Membership Model (SS3M) a probabilistic
                  graphical model for learning disease phenotypes from
                  partially labeled clinical data. We show SS3M can
                  generate interpretable, disease-specific phenotypes
                  which capture the clinical features of the disease
                  concepts specified by the labels provided to the
                  model. Furthermore, SS3M phenotypes demonstrate
                  competitive predictive performance relative to
                  commonly used baselines.},
  Author =	 {Rodriguez, Victor A. and Perotte, Adler},
  Booktitle =	 {Proceedings of the 4th Machine Learning for
                  Healthcare Conference},
  Pages =	 {304-324},
  Title =	 {Phenotype Inference with Semi-Supervised Mixed
                  Membership Models},
  Volume =	 {106},
  Year =	 {2019}
}

@inproceedings{Pfohl19,
  Abstract =	 {The use of machine learning systems to support
                  decision making in healthcare raises questions as to
                  what extent these systems may introduce or
                  exacerbate disparities in care for historically
                  underrepresented and mistreated groups, due to
                  biases implicitly embedded in observational data in
                  electronic health records. To address this problem
                  in the context of clinical risk prediction models,
                  we develop an augmented counterfactual fairness
                  criteria that extends the group fairness criteria of
                  equalized odds. We do so by requiring that the same
                  prediction be made for a patient, and a
                  counterfactual patient resulting from changing a
                  sensitive attribute, if the factual and
                  counterfactual outcomes do not differ. We
                  investigate the extent to which the augmented
                  counterfactual fairness criteria may be applied to
                  develop fair models for prolonged inpatient length
                  of stay and mortality with observational electronic
                  health records data. As the fairness criteria is
                  ill-defined without knowledge of the data generating
                  process, we use a variational autoencoder to perform
                  counterfactual inference in the context of an
                  assumed causal graph. While our technique provides a
                  means to trade off maintenance of fairness with
                  reduction in predictive performance in the context
                  of a learned generative model, further work is
                  needed to assess the generality of this approach.},
  Author =	 {Pfohl, Stephen R. and Duan, Tony and Ding, Daisy Yi
                  and Shah, Nigam H.},
  Booktitle =	 {Proceedings of the 4th Machine Learning for
                  Healthcare Conference},
  Pages =	 {325-358},
  Title =	 {Counterfactual Reasoning for Fair Clinical Risk
                  Prediction},
  Volume =	 {106},
  Year =	 {2019}
}

@inproceedings{Tonekaboni19,
  Abstract =	 {Translating machine learning (ML) models effectively
                  to clinical practice requires establishing
                  clinicians' trust. Explainability, or the ability of
                  an ML model to justify its outcomes and assist
                  clinicians in rationalizing the model prediction,
                  has been generally understood to be critical to
                  establishing trust. However, the eld suffers from
                  the lack of concrete definitions for usable
                  explanations in different settings. To identify
                  specific aspects of explainability that may catalyze
                  building trust in ML models, we surveyed clinicians
                  from two distinct acute care specialties (Intenstive
                  Care Unit and Emergency Department). We use their
                  feedback to characterize when explainability helps
                  to improve clinicians' trust in ML models. We
                  further identify the classes of explanations that
                  clinicians identified as most relevant and crucial
                  for effective translation to clinical
                  practice. Finally, we discern concrete metrics for
                  rigorous evaluation of clinical explainability
                  methods. By integrating perceptions of
                  explainability between clinicians and ML researchers
                  we hope to facilitate the endorsement and broader
                  adoption and sustained use of ML systems in
                  healthcare.},
  Author =	 {Tonekaboni, Sana and Joshi, Shalmali and McCradden,
                  Melissa D. and Goldenberg, Anna},
  Booktitle =	 {Proceedings of the 4th Machine Learning for
                  Healthcare Conference},
  Pages =	 {359-380},
  Title =	 {What Clinicians Want: Contextualizing Explainable
                  Machine Learning for Clinical End Use},
  Volume =	 {106},
  Year =	 {2019}
}

@inproceedings{Nestor19,
  Abstract =	 {When training clinical prediction models from
                  electronic health records (EHRs), a key concern
                  should be a model’s ability to sustain performance
                  over time when deployed, even as care practices,
                  database systems, and population demographics
                  evolve. Due to de-identification requirements,
                  however, current experimental practices for public
                  EHR benchmarks (such as the MIMIC-III critical care
                  dataset) are time agnostic, assigning care records
                  to train or test sets without regard for the actual
                  dates of care. As a result, current benchmarks
                  cannot assess how well models trained on one year
                  generalise to another. In this work, we obtain a
                  Limited Data Use Agreement to access year of care
                  for each record in MIMIC and show that all tested
                  state-of-the-art models decay in prediction quality
                  when trained on historical data and tested on future
                  data, particularly in response to a system-wide
                  record-keeping change in 2008 (0.29 drop in AUROC
                  for mortality prediction, 0.10 drop in AUROC for
                  length-of-stay prediction with a random forest
                  classifier). We further develop a simple yet
                  effective mitigation strategy: by aggregating raw
                  features into expert-defined clinical concepts, we
                  see only a 0.06 drop in AUROC for mortality
                  prediction and a 0.03 drop in AUROC for
                  length-of-stay prediction. We demonstrate that this
                  aggregation strategy outperforms other automatic
                  feature preprocessing techniques aimed at increasing
                  robustness to data drift. We release our aggregated
                  representations and code1 to encourage more
                  deployable clinical prediction models.},
  Author =	 {Nestor, Bret and McDermott, Matthew B. A. and Boag,
                  Willie and Berner, Gabriela and Naumann, Tristan and
                  Hughes, Michael C. and Goldenberg, Anna and
                  Ghassemi, Marzyeh},
  Booktitle =	 {Feature Robustness in Non-stationary Health Records:
                  Caveats to Deployable Model Performance in Common
                  Clinical Machine Learning Tasks},
  Pages =	 {381-405},
  Title =	 {Bayesian Trees for Automated Cytometry Data
                  Analysis},
  Volume =	 {106},
  Year =	 {2019}
}

@inproceedings{Thawani19,
  Abstract =	 {Patients increasingly seek out information regarding
                  their healthcare online. Online reviews of
                  caregivers in particular may influence from whom
                  patients seek treatment. Are these sources biased
                  against female providers? To address this question
                  we analyze a new dataset of online patient reviews
                  of male and female healthcare providers with respect
                  to numerical ratings and language use. We perform
                  both regression and (data-driven) qualitative
                  analyses of language via neural embedding models
                  induced over review texts. In both cases we account
                  for provider specialty. To do so while learning
                  embeddings, we explicitly induce specialty, sex, and
                  rating embeddings from review meta-data via a
                  ‘matched-sampling’ training regime. We find that
                  females consistently receive less favorable
                  numerical ratings overall, even after adjusting for
                  specialty. To analyze language use in reviews of
                  male versus female providers, we induce neural
                  embeddings (distributed representations) of gender
                  and qualitatively characterize the ‘distributional
                  semantics’ that this induces. We observe differences
                  in language use, e.g., analysis of average vector
                  similarities over repeated runs reveal that many of
                  the words closest to the coordinates in embedding
                  space associated with positive sentiment and female
                  providers describe interpersonal characteristics
                  (sweet , considerate , caring , personable ,
                  compassionate ): such descriptors do not seem as
                  similar to the point corresponding to positive
                  sentiment regarding male providers. To facilitate
                  research in this direction we publicly release data,
                  embeddings, and all code (including Jupyter
                  notebooks) to reproduce our analyses and further
                  explore the data:
                  https://github.com/avi-jit/RateMDs.},
  Author =	 {Thawani, Avijit and Paul, Michael J. and Sarkar,
                  Urmimala and Wallace, Byron C.},
  Booktitle =	 {Proceedings of the 4th Machine Learning for
                  Healthcare Conference},
  Pages =	 {406-423},
  Title =	 {Are Online Reviews of Physicians Biased Against
                  Female Providers?},
  Volume =	 {106},
  Year =	 {2019}
}

@inproceedings{Yadlowsky19,
  Abstract =	 {We study methods for assessing the degree of
                  systematic over- or under- estimation, known as
                  calibration, of a learned risk model in an
                  independent validation cohort. Here, we advance
                  methods for evaluating clinical risk prediction
                  models by deriving a population parameter measuring
                  the average calibration error of the predicted risk
                  from the true risk, and providing a method for
                  estimation and inference. Our approach improves upon
                  commonly-used goodness of t tests that depends on
                  subjective bin thresholding and may yield misleading
                  results by reporting confidence intervals for the
                  calibration error instead of a simple P-value that
                  conflate calibration error and sample size. This
                  approach enables comparison among multiple risk
                  prediction models, and can guide model revision. We
                  illustrate how our new method helps to understand
                  the calibration of risk models that have been
                  profoundly influential in clinical practice, but
                  controversial due to their potential
                  miscalibration.},
  Author =	 {Yadlowsky, Steve and Basu, Sanjay and Tian, Lu},
  Booktitle =	 {Proceedings of the 4th Machine Learning for
                  Healthcare Conference},
  Pages =	 {424-450},
  Title =	 {A Calibration Metric for Risk Scores with Survival
                  Data},
  Volume =	 {106},
  Year =	 {2019}
}

@inproceedings{Yoon19,
  Abstract =	 {Deciding what and when to observe is critical when
                  making observations is costly. In a medical setting
                  where observations can be made sequentially , making
                  these observations (or not) should be an active
                  choice. We refer to this as the active sensing
                  problem. In this paper, we propose a novel deep
                  learning framework, which we call ASAC (Active
                  Sensing using Actor-Critic models) to address this
                  problem. ASAC consists of two networks: a selector
                  network and a predictor network. The selector
                  network uses previously selected observations to
                  determine what should be observed in the future. The
                  predictor network uses the observations selected by
                  the selector network to predict a label, providing
                  feedback to the selector network (well-selected
                  variables should be predictive of the label). The
                  goal of the selector network is then to select
                  variables that balance the cost of observing the
                  selected variables with their predictive power; we
                  wish to preserve the conditional label
                  distribution. During training, we use the
                  actor-critic models to allow the loss of the
                  selector to be “back-propagated" through the
                  sampling process. The selector network “acts" by
                  selecting future observations to make. The predictor
                  network acts as a “critic" by feeding predictive
                  errors for the selected variables back to the
                  selector network. In our experiments, we show that
                  ASAC significantly outperforms state-of-the-arts in
                  two real-world medical datasets.},
  Author =	 {Yoon, Jinsung and Jordon, James and van der Schaar,
                  Mihaela},
  Booktitle =	 {Proceedings of the 4th Machine Learning for
                  Healthcare Conference},
  Pages =	 {451-473},
  Title =	 {ASAC: Active Sensing using Actor-Critic models},
  Volume =	 {106},
  Year =	 {2019}
}

@inproceedings{Zheng19,
  Abstract =	 {Increasingly large observational datasets from
                  healthcare and social media may allow new types of
                  causal inference. However, these data are often
                  missing key variables, increasing the chance of
                  finding spurious causal relationships due to
                  confounding. While methods exist for causal
                  inference with latent variables in static cases,
                  temporal relationships are more challenging, as
                  varying time lags make latent causes more difficult
                  to uncover and approaches often have significantly
                  higher computational complexity. To address this, we
                  make the key observation that while a variable may
                  be latent in one dataset, it may be observed in
                  another, or we may have domain knowledge about its
                  effects. We propose a computationally efficient
                  method that overcomes latent variables by using
                  prior knowledge to reconstruct data for unobserved
                  variables, while remaining robust to cases when the
                  knowledge is wrong or does not apply. On simulated
                  data, our approach outperforms the state of the art
                  with a lower false discovery rate for causal
                  inference. On real-world data from individuals with
                  Type 1 diabetes, we show that our approach can
                  discover causal relationships involving unmeasured
                  meals and exercise.},
  Author =	 {Zheng, Min and Kleinberg, Samantha},
  Booktitle =	 {Proceedings of the 4th Machine Learning for
                  Healthcare Conference},
  Pages =	 {474-489},
  Title =	 {Using Domain Knowledge to Overcome Latent Variables
                  in Causal Inference from Time Series},
  Volume =	 {106},
  Year =	 {2019}
}

@inproceedings{Zhang19,
  Abstract =	 {The treatment effects of medications play a key role
                  in guiding medical prescriptions. They are usually
                  assessed with randomized controlled trials (RCTs),
                  which are expensive. Recently, large-scale
                  electronic health records (EHRs) have become
                  available, opening up new opportunities for more
                  cost-effective assessments. However, assessing a
                  treatment effect from EHRs is challenging: it is
                  biased by unobserved confounders , unmeasured
                  variables that affect both patients’ medical
                  prescription and their outcome, e.g. the patients’
                  social economic status. To adjust for unobserved
                  confounders, we develop the medical deconfounder , a
                  machine learning algorithm that unbiasedly estimates
                  treatment effects from EHRs. The medical
                  deconfounder first constructs a substitute
                  confounder by modeling which medications were
                  prescribed to each patient; this substitute
                  confounder is guaranteed to capture all
                  multi-medication confounders, observed or unobserved
                  (Wang and Blei , 2018 ). It then uses this
                  substitute confounder to adjust for the confounding
                  bias in the analysis. We validate the medical
                  deconfounder on two simulated and two real medical
                  data sets. Compared to classical approaches, the
                  medical deconfounder produces closer-to-truth
                  treatment effect estimates; it also identifies
                  effective medications that are more consistent with
                  the findings in the medical literature.},
  Author =	 {Zhang, Linying and Wang, Yixin and Ostropolets, Anna
                  and Mulgrave, Jami J. and Blei, David M. and
                  Hripcsak, George},
  Booktitle =	 {Proceedings of the 4th Machine Learning for
                  Healthcare Conference},
  Pages =	 {490-512},
  Title =	 {The Medical Deconfounder: Assessing Treatment
                  Effects with Electronic Health Records},
  Volume =	 {106},
  Year =	 {2019}
}

@inproceedings{Biswal19,
  Abstract =	 {Electroencephalography (EEG) is widely used in
                  hospitals and clinics for the diagnosis of many
                  neurological conditions. Such diagnoses require
                  accurate and timely clinical reports to summarize
                  the findings from raw EEG data. In this paper, we
                  investigate whether it is possible to automatically
                  generate text reports directly from EEG data. To
                  address the challenges, we proposed EEGtoText ,
                  which first extracted shift invariant and temporal
                  patterns using stacked convolutional neural networks
                  and recurrent neural networks (RCNN). These temporal
                  patterns are used to classify key phenotypes
                  including EEG normality, sleep, generalized and
                  focal slowing, epileptiform discharges, spindles,
                  vertex waves and seizures. Based on these
                  phenotypes, the impression section of the EEG report
                  is generated. Next, we adopted a hierarchical long
                  short-term memory network(LSTM) that comprises of
                  paragraph-level and sentence-level LSTMs to generate
                  the detail explanation of the impression. Within the
                  hierarchical LSTM, we used an attention module to
                  localize the abnormal areas in the EEG which provide
                  another explanation and justification of the
                  extracted phenotypes. We conducted large-scale
                  evaluations on two different EEG datasets Dataset1
                  (n=12,980) and TUH (n=16,950). We achieved an area
                  under the ROC curve (AUC) between .658 to .915 on
                  phenotype classification, which is significantly
                  higher than CRNN and RCNN with attention. We also
                  conducted a quantitative evaluation of the detailed
                  explanation, which achieved METEOR score .371 and
                  BLEU score 4.583. Finally, our initial clinical
                  reviews confirmed the effectiveness of the generated
                  reports.},
  Author =	 {Biswal, Siddharth and Xiao, Cao and Westover,
                  M. Brandon and Sun, Jimeng},
  Booktitle =	 {Proceedings of the 4th Machine Learning for
                  Healthcare Conference},
  Pages =	 {513-531},
  Title =	 {EEGtoText: Learning to Write Medical Reports from
                  EEG Recordings},
  Volume =	 {106},
  Year =	 {2019}
}

@inproceedings{Prabhu19,
  Abstract =	 {We consider the problem of clinical image
                  classification for the purpose of aiding doctors in
                  dermatological disease diagnosis. Diagnosis of
                  dermatological conditions from images poses two
                  major challenges for standard off-the-shelf
                  techniques: First, the distribution of real-world
                  dermatological datasets is typically
                  long-tailed. Second, intra-class variability is
                  large. To address the first issue, we formulate the
                  problem as low-shot learning, where once deployed, a
                  base classifier must rapidly generalize to diagnose
                  novel conditions given very few labeled examples. To
                  model intra-class variability effectively, we
                  propose Prototypical Clustering Networks (PCN), an
                  extension to Prototypical Networks (Snell et al. ,
                  2017 ) that learns a mixture of “prototypes” for
                  each class. Prototypes are initialized for each
                  class via clustering and refined via an online
                  update scheme. Classification is performed by
                  measuring similarity to a weighted combination of
                  prototypes within a class, where the weights are the
                  inferred cluster responsibilities. We demonstrate
                  the strengths of our approach in effective diagnosis
                  on a realistic dataset of dermatological
                  conditions.},
  Author =	 {Prabhu, Viraj and Kannan, Anitha and Ravuri, Murali
                  and Chaplain, Manish and Sontag, David and
                  Amatriain, Xavier},
  Booktitle =	 {Proceedings of the 4th Machine Learning for
                  Healthcare Conference},
  Pages =	 {532-552},
  Title =	 {Few-Shot Learning for Dermatological Disease
                  Diagnosis},
  Volume =	 {106},
  Year =	 {2019}
}

@inproceedings{Dov19,
  Abstract =	 {We consider preoperative prediction of thyroid
                  cancer based on ultra-high-resolution whole-slide
                  cytopathology images. Inspired by how human experts
                  perform diagnosis, our approach first identifies and
                  classifies diagnostic image regions containing
                  informative thyroid cells, which only comprise a
                  tiny fraction of the entire image. These local
                  estimates are then aggregated into a single
                  prediction of thyroid malignancy. Several unique
                  characteristics of thyroid cytopathology guide our
                  deep-learning-based approach. While our method is
                  closely related to multiple-instance learning, it
                  deviates from these methods by using a supervised
                  procedure to extract diagnostically relevant
                  regions. Moreover, we propose to simultaneously
                  predict thyroid malignancy, as well as a diagnostic
                  score assigned by a human expert, which further
                  allows us to devise an improved training
                  strategy. Experimental results show that the
                  proposed algorithm achieves performance comparable
                  to human experts, and demonstrate the potential of
                  using the algorithm for screening and as an
                  assistive tool for the improved diagnosis of
                  indeterminate cases.},
  Author =	 {Dov, David and Kovalsky, Shahar Z. and Cohen,
                  Jonathan and Range, Danielle Elliott and Henao,
                  Ricardo and Carin, Lawrence},
  Booktitle =	 {Proceedings of the 4th Machine Learning for
                  Healthcare Conference},
  Pages =	 {553-570},
  Title =	 {Thyroid Cancer Malignancy Prediction From Whole
                  Slide Cytopathology Images},
  Volume =	 {106},
  Year =	 {2019}
}

@inproceedings{Kyono19,
  Abstract =	 {The number of women requiring screening and
                  diagnostic mammography is increasing. The recent
                  promise of machine learning on medical images have
                  led to an influx of studies using deep learning for
                  autonomous mammogram diagnosis. We present a novel
                  multi-view multi-task (MVMT) convolutional neural
                  network (CNN) trained to predict the radiological
                  assessments known to be associated with cancer, such
                  as breast density, conspicuity, etc., in addition to
                  cancer diagnosis. We show on full-eld mammograms
                  that multi-task learning has three advantages: 1)
                  learning refined feature representations associated
                  with cancer improves the classification performance
                  of the diagnosis task, 2) issuing radiological
                  assessments provides an additional layer of model
                  interpretability that a radiologist can use to debug
                  and scrutinize the diagnoses provided by the CNN,
                  and 3) improves the radiological workflow by
                  providing automated annotation of radiological
                  reports. Results obtained on a private dataset of
                  over 7,000 patients show that our MVMT network
                  attained an AUROC and AUPRC of 0.855 $\pm$ 0.021 and
                  0.646 $\pm$ 0.023, respectively, and improved on the
                  performance of other state-of-the-art multi-view
                  CNNs.},
  Author =	 {Kyono, Trent and Gilbert, Fiona J. and van der
                  Schaar, Mihaela},
  Booktitle =	 {Proceedings of the 4th Machine Learning for
                  Healthcare Conference},
  Pages =	 {571-591},
  Title =	 {Multi-view Multi-task Learning for Improving
                  Autonomous Mammogram Diagnosis},
  Volume =	 {106},
  Year =	 {2019}
}

@inproceedings{Lee19,
  Abstract =	 {Given the crucial role of microtubules for cell
                  survival, many researchers have found success using
                  microtubule-targeting agents in the search for
                  effective cancer therapeutics. Understanding
                  microtubule responses to targeted interventions
                  requires that the microtubule network within cells
                  can be consistently observed across a large sample
                  of images. However, fluorescence noise sources
                  captured simultaneously with biological signals
                  while using wide-held microscopes can obfuscate fine
                  microtubule structures. Such requirements are
                  particularly challenging for high-throughput
                  imaging, where researchers must make decisions
                  related to the trade-off between imaging quality and
                  speed. Here, we propose a computational framework to
                  enhance the quality of high-throughput imaging data
                  to achieve fast speed and high quality
                  simultaneously. Using CycleGAN, we learn an image
                  model from low-throughput, high-resolution images to
                  enhance features, such as microtubule networks in
                  high-throughput low-resolution images. We show that
                  CycleGAN is effective in identifying microtubules
                  with 0.93+ AUC-ROC and that these results are robust
                  to different kinds of image noise. We further apply
                  CycleGAN to quantify the changes in microtubule
                  density as a result of the application of drug
                  compounds, and show that the quantified responses
                  correspond well with known drug effects.},
  Author =	 {Lee, Hao-Chih and Cherng, Sarah T. and Miotto,
                  Riccardo and Dudley, Joel T.},
  Booktitle =	 {Proceedings of the 4th Machine Learning for
                  Healthcare Conference},
  Pages =	 {592-613},
  Title =	 {Enhancing high-content imaging for studying
                  microtubule networks at large-scale},
  Volume =	 {106},
  Year =	 {2019}
}

@inproceedings{Hamesse19,
  Abstract =	 {Achilles Tendon Rupture (ATR) is one of the typical
                  soft tissue injuries. Rehabilitation after such a
                  musculoskeletal injury remains a prolonged process
                  with a very variable outcome. Accurately predicting
                  rehabilitation outcome is crucial for treatment
                  decision support. However, it is challenging to
                  train an automatic method for predicting the ATR
                  rehabilitation outcome from treatment data, due to a
                  massive amount of missing entries in the data
                  recorded from ATR patients, as well as complex
                  nonlinear relations between measurements and
                  outcomes. In this work, we design an end-to-end
                  probabilistic framework to impute missing data
                  entries and predict rehabilitation outcomes
                  simultaneously. We evaluate our model on a real-life
                  ATR clinical cohort, comparing with various
                  baselines. The proposed method demonstrates its
                  clear superiority over traditional methods which
                  typically perform imputation and prediction in two
                  separate stages.},
  Author =	 {Hamesse, Charles and Tu, Ruibo and Ackermann, Paul
                  and Kjellstr{\"{o}}m, Hedvig and Zhang, Cheng},
  Booktitle =	 {Proceedings of the 4th Machine Learning for
                  Healthcare Conference},
  Pages =	 {614-640},
  Title =	 {Simultaneous Measurement Imputation and Outcome
                  Prediction for Achilles Tendon Rupture
                  Rehabilitation},
  Volume =	 {106},
  Year =	 {2019}
}

@inproceedings{Mirtchouk19,
  Abstract =	 {Nutrition is fundamental to maintaining health,
                  managing chronic diseases, and preventing illness,
                  but unlike physical activity there is not yet a way
                  to unobtrusively and automatically measure
                  nutrition. While recent work has shown that
                  body-worn sensors can be used to identify meal
                  times, to have an impact on health and fully replace
                  manual food logs, we need to identify not only when
                  someone is eating, but what they are
                  consuming. However, it is challenging to collect
                  labeled data in daily life, while lab data does not
                  always generalize to reality. To address this, we
                  develop new algorithms for semi-supervised
                  hierarchical classification that enable higher
                  accuracy when training on data with weak
                  labels. Using this approach, we present the first
                  results on automated classification of foods
                  consumed in data collected from body-worn audio and
                  motion sensors in free-living environments. We show
                  that by exploiting a mix of lab and free-living
                  data, we can achieve a classification accuracy of
                  88% on unrestricted meals (e.g. stir fry, pizza,
                  salad) in unrestricted environments such as home and
                  restaurants. Ultimately, this lays the foundation
                  for body-worn devices that can calculate calories
                  and macronutrients by identifying food type and
                  quantity.},
  Author =	 {Mirtchouk, Mark and McGuire, Dana L. and Deierlein,
                  Andrea L. and Kleinberg, Samantha},
  Booktitle =	 {Proceedings of the 4th Machine Learning for
                  Healthcare Conference},
  Pages =	 {641-662},
  Title =	 {Automated Estimation of Food Type from Body-worn
                  Audio and Motion Sensors in Free-Living
                  Environments},
  Volume =	 {106},
  Year =	 {2019}
}

@inproceedings{Lau19,
  Abstract =	 {To optimize clinical outcomes, fertility clinics
                  must strategically select which embryos to
                  transfer. Common selection heuristics are formulas
                  expressed in terms of the durations required to
                  reach various developmental milestones, quantities
                  historically annotated manually by experienced
                  embryologists based on time-lapse EmbryoScope
                  videos. We propose a new method for automatic embryo
                  staging that exploits several sources of structure
                  in this time-lapse data. First, noting that in each
                  image the embryo occupies a small subregion, we
                  jointly train a region proposal network with the
                  downstream classier to isolate the embryo. Notably,
                  because we lack ground-truth bounding boxes, our we
                  weakly supervise the region proposal network
                  optimizing its parameters via reinforcement learning
                  to improve the downstream classier's loss. Moreover,
                  noting that embryos reaching the blastocyst stage
                  progress monotonically through earlier stages, we
                  develop a dynamic-programming-based decoder that
                  post-processes our predictions to select the most
                  likely monotonic sequence of developmental
                  stages. Our methods outperform vanilla residual
                  networks and rival the best numbers in contemporary
                  papers, as measured by both per-frame accuracy and
                  transition prediction error, despite operating on
                  smaller data than many.},
  Author =	 {Lau, Tingfung and Ng, Nathan and Gingold, Julian and
                  Desai, Nina and McAuley, Julian and Lipton, Zachary
                  C.},
  Booktitle =	 {Proceedings of the 4th Machine Learning for
                  Healthcare Conference},
  Pages =	 {663-679},
  Title =	 {Embryo Staging with Weakly-Supervised Region
                  Selection and Dynamically-Decoded Predictions},
  Volume =	 {106},
  Year =	 {2019}
}

@inproceedings{Kaul19,
  Abstract =	 {Brief, intense exercise can improve health due to
                  its acute effect on the autonomic nervous system,
                  particularly the sympathetic nervous
                  system. Salivary amylase is a marker of sympathetic
                  activity during exercise, but it requires
                  specialized equipment to measure. We investigate the
                  feasibility of estimating the amylase response from
                  heartbeat data recorded by commodity sensors. We
                  collect heartbeat and amylase data for n = 71
                  sessions of intense exercise performed in a
                  commercial setting. Our machine learning model
                  exploits structure in the heartbeat signal: by
                  identifying and removing the contribution of the
                  parasympathetic nervous system, we obtain a residual
                  with sympathetic information, to which we apply a
                  convolutional neural network. This model has better
                  accuracy than existing measures of exercise
                  response, such as maximum heart rate, even though it
                  doesn’t use metadata such as age and gender. This
                  suggests sympathetic activity may be (weakly)
                  discerned from heartbeat data. With a larger
                  dataset, a practical measure of sympathetic response
                  to exercise could potentially be developed. Our
                  quantification of parasympathetic activity is more
                  powerful than existing approaches and may have
                  independent value.},
  Author =	 {Kaul, Shiva and Falco, Anthony and Anthes, Karianne},
  Booktitle =	 {Proceedings of the 4th Machine Learning for
                  Healthcare Conference},
  Pages =	 {680-703},
  Title =	 {Measuring the Sympathetic Response to Intense
                  Exercise in a Practical Setting},
  Volume =	 {106},
  Year =	 {2019}
}

@inproceedings{Ortiz19,
  Abstract =	 {Recently, researchers have started training high
                  complexity machine learning models to clinical
                  tasks, often improving upon previous
                  benchmarks. However, more often than not, these
                  methods require large amounts of supervision to
                  provide good generalization guarantees. When applied
                  to data coming from small cohorts and long
                  monitoring periods these models are prone to overt
                  to subject-identifying features. Since obtaining
                  large amounts of labels is usually not practical in
                  many scenarios, expert-driven knowledge of the task
                  is a common technique to prevent overfitting. We
                  present a two-step learning approach that is able to
                  generalize under these circumstances when applied to
                  a voice monitoring dataset. Our approach decouples
                  the feature learning stage and performs it in an
                  unsupervised manner, removing the need for laborious
                  feature engineering. We show the effectiveness of
                  our proposed model on two voice monitoring related
                  tasks. We evaluate the extracted features for
                  classifying between patients with vocal fold nodules
                  and controls. We also demonstrate that the features
                  capture pathology relevant information by showing
                  that models trained on them are more accurate
                  predicting vocal use for patients than for
                  controls. Our proposed method is able to generalize
                  to unseen subjects and across learning tasks while
                  matching state-of-the-art results.},
  Author =	 {Ortiz, Jose Javier Gonzalez and Mehta, Daryush
                  D. and Van Stan, Jarrad H. and Hillman, Robert and
                  Guttag, John V. and Ghassemi, Marzeyeh},
  Booktitle =	 {Proceedings of the 4th Machine Learning for
                  Healthcare Conference},
  Pages =	 {704-720},
  Title =	 {Learning from Few Subjects with Large Amounts of
                  Voice Monitoring Data},
  Volume =	 {106},
  Year =	 {2019}
}

@inproceedings{Al-Hussaini19,
  Abstract =	 {Sleep staging is a crucial task for diagnosing sleep
                  disorders. It is tedious and complex as it can take
                  a trained expert several hours to annotate just one
                  patient's polysomnogram (PSG) from a single
                  night. Although deep learning models have
                  demonstrated state-of-the-art performance in
                  automating sleep staging, interpretability which
                  defines other desiderata, has largely remained
                  unexplored. In this study, we propose Sleep staging
                  via Prototypes from Expert Rules (SLEEPER ), which
                  combines deep learning models with expert defined
                  rules using a prototype learning framework to
                  generate simple interpretable models. In particular,
                  SLEEPER utilizes sleep scoring rules and expert
                  defined features to derive prototypes which are
                  embeddings of PSG data fragments via convolutional
                  neural networks. The final models are simple
                  interpretable models like a shallow decision tree
                  defined over those phenotypes. We evaluated SLEEPER
                  using two PSG datasets collected from sleep studies
                  and demonstrated that SLEEPER could provide accurate
                  sleep stage classification comparable to human
                  experts and deep neural networks with about 85\%
                  ROC-AUC and .7 $\kappa$.},
  Author =	 {Al-Hussaini, Irfan and Xiao, Cao and Westover,
                  M. Brandon and Sun, Jimeng},
  Booktitle =	 {Proceedings of the 4th Machine Learning for
                  Healthcare Conference},
  Pages =	 {721-739},
  Title =	 {SLEEPER: interpretable Sleep staging via Prototypes
                  from Expert Rules},
  Volume =	 {106},
  Year =	 {2019}
}

